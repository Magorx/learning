{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import model_selection, linear_model, metrics\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"Tweets data.csv\", encoding = \"ISO-8859-1\")\n",
    "target = tweets['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_trick(s):\n",
    "    s.lower()\n",
    "    n = 199\n",
    "    tarr = np.zeros(n)\n",
    "    gramm_size = 2\n",
    "    for i in range(len(s) - gramm_size):\n",
    "        tarr[hash(s[i:i+gramm_size]) % n] += 1\n",
    "\n",
    "    return pd.Series(tarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tweets.SentimentText.apply(hash_trick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(data, target, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = xgb.DMatrix(X_train, Y_train)\n",
    "pool_test = xgb.DMatrix(X_test, Y_test)\n",
    "params = {'eta' : 0.3, 'objective' : 'binary:logistic', 'max_depth':3, 'eval_metric' : ['auc', 'logloss']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.597143\ttrain-logloss:0.680435\ttest-auc:0.591677\ttest-logloss:0.681087\n",
      "Multiple eval metrics have been passed: 'test-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-logloss hasn't improved in 5 rounds.\n",
      "[1]\ttrain-auc:0.615144\ttrain-logloss:0.673446\ttest-auc:0.607988\ttest-logloss:0.674804\n",
      "[2]\ttrain-auc:0.630112\ttrain-logloss:0.667419\ttest-auc:0.623233\ttest-logloss:0.669108\n",
      "[3]\ttrain-auc:0.640891\ttrain-logloss:0.663101\ttest-auc:0.634661\ttest-logloss:0.664966\n",
      "[4]\ttrain-auc:0.646031\ttrain-logloss:0.659759\ttest-auc:0.638836\ttest-logloss:0.662047\n",
      "[5]\ttrain-auc:0.653171\ttrain-logloss:0.657021\ttest-auc:0.645895\ttest-logloss:0.659429\n",
      "[6]\ttrain-auc:0.659656\ttrain-logloss:0.65384\ttest-auc:0.653844\ttest-logloss:0.656117\n",
      "[7]\ttrain-auc:0.664945\ttrain-logloss:0.651674\ttest-auc:0.658294\ttest-logloss:0.654269\n",
      "[8]\ttrain-auc:0.67059\ttrain-logloss:0.649669\ttest-auc:0.662479\ttest-logloss:0.652747\n",
      "[9]\ttrain-auc:0.676085\ttrain-logloss:0.646786\ttest-auc:0.667543\ttest-logloss:0.650078\n",
      "[10]\ttrain-auc:0.679617\ttrain-logloss:0.645135\ttest-auc:0.670533\ttest-logloss:0.648669\n",
      "[11]\ttrain-auc:0.68253\ttrain-logloss:0.643324\ttest-auc:0.67282\ttest-logloss:0.647048\n",
      "[12]\ttrain-auc:0.686121\ttrain-logloss:0.64155\ttest-auc:0.676264\ttest-logloss:0.64538\n",
      "[13]\ttrain-auc:0.688115\ttrain-logloss:0.64005\ttest-auc:0.677767\ttest-logloss:0.644117\n",
      "[14]\ttrain-auc:0.692271\ttrain-logloss:0.637958\ttest-auc:0.682123\ttest-logloss:0.642075\n",
      "[15]\ttrain-auc:0.694557\ttrain-logloss:0.636483\ttest-auc:0.684033\ttest-logloss:0.640755\n",
      "[16]\ttrain-auc:0.69591\ttrain-logloss:0.634899\ttest-auc:0.685951\ttest-logloss:0.639239\n",
      "[17]\ttrain-auc:0.697929\ttrain-logloss:0.6338\ttest-auc:0.687248\ttest-logloss:0.638437\n",
      "[18]\ttrain-auc:0.699774\ttrain-logloss:0.632729\ttest-auc:0.689249\ttest-logloss:0.637385\n",
      "[19]\ttrain-auc:0.701554\ttrain-logloss:0.631529\ttest-auc:0.691139\ttest-logloss:0.636393\n",
      "[20]\ttrain-auc:0.703408\ttrain-logloss:0.630556\ttest-auc:0.692971\ttest-logloss:0.635367\n",
      "[21]\ttrain-auc:0.704772\ttrain-logloss:0.629429\ttest-auc:0.69437\ttest-logloss:0.63433\n",
      "[22]\ttrain-auc:0.706032\ttrain-logloss:0.628408\ttest-auc:0.695302\ttest-logloss:0.633511\n",
      "[23]\ttrain-auc:0.708028\ttrain-logloss:0.627234\ttest-auc:0.696979\ttest-logloss:0.632546\n",
      "[24]\ttrain-auc:0.709196\ttrain-logloss:0.626203\ttest-auc:0.698391\ttest-logloss:0.631568\n",
      "[25]\ttrain-auc:0.710625\ttrain-logloss:0.625147\ttest-auc:0.699288\ttest-logloss:0.63078\n",
      "[26]\ttrain-auc:0.712163\ttrain-logloss:0.624166\ttest-auc:0.700648\ttest-logloss:0.629901\n",
      "[27]\ttrain-auc:0.713139\ttrain-logloss:0.622427\ttest-auc:0.702036\ttest-logloss:0.628123\n",
      "[28]\ttrain-auc:0.714128\ttrain-logloss:0.621198\ttest-auc:0.703163\ttest-logloss:0.626922\n",
      "[29]\ttrain-auc:0.715207\ttrain-logloss:0.620504\ttest-auc:0.704505\ttest-logloss:0.626182\n",
      "[30]\ttrain-auc:0.716244\ttrain-logloss:0.61976\ttest-auc:0.705489\ttest-logloss:0.625544\n",
      "[31]\ttrain-auc:0.717452\ttrain-logloss:0.618906\ttest-auc:0.706594\ttest-logloss:0.62473\n",
      "[32]\ttrain-auc:0.71878\ttrain-logloss:0.618046\ttest-auc:0.707481\ttest-logloss:0.624103\n",
      "[33]\ttrain-auc:0.719758\ttrain-logloss:0.617244\ttest-auc:0.708122\ttest-logloss:0.623579\n",
      "[34]\ttrain-auc:0.720905\ttrain-logloss:0.616559\ttest-auc:0.70857\ttest-logloss:0.623251\n",
      "[35]\ttrain-auc:0.721803\ttrain-logloss:0.615797\ttest-auc:0.709473\ttest-logloss:0.622556\n",
      "[36]\ttrain-auc:0.722698\ttrain-logloss:0.615045\ttest-auc:0.709707\ttest-logloss:0.62211\n",
      "[37]\ttrain-auc:0.723676\ttrain-logloss:0.614398\ttest-auc:0.710544\ttest-logloss:0.621547\n",
      "[38]\ttrain-auc:0.724837\ttrain-logloss:0.613555\ttest-auc:0.711195\ttest-logloss:0.620951\n",
      "[39]\ttrain-auc:0.72568\ttrain-logloss:0.612939\ttest-auc:0.711897\ttest-logloss:0.620453\n",
      "[40]\ttrain-auc:0.7262\ttrain-logloss:0.612324\ttest-auc:0.712158\ttest-logloss:0.620072\n",
      "[41]\ttrain-auc:0.727218\ttrain-logloss:0.611616\ttest-auc:0.712986\ttest-logloss:0.619527\n",
      "[42]\ttrain-auc:0.728267\ttrain-logloss:0.6106\ttest-auc:0.713626\ttest-logloss:0.618809\n",
      "[43]\ttrain-auc:0.728668\ttrain-logloss:0.610028\ttest-auc:0.713935\ttest-logloss:0.618335\n",
      "[44]\ttrain-auc:0.730096\ttrain-logloss:0.609127\ttest-auc:0.715099\ttest-logloss:0.617655\n",
      "[45]\ttrain-auc:0.731143\ttrain-logloss:0.608215\ttest-auc:0.716098\ttest-logloss:0.616903\n",
      "[46]\ttrain-auc:0.731605\ttrain-logloss:0.607803\ttest-auc:0.716568\ttest-logloss:0.616501\n",
      "[47]\ttrain-auc:0.732115\ttrain-logloss:0.607336\ttest-auc:0.716608\ttest-logloss:0.616362\n",
      "[48]\ttrain-auc:0.732721\ttrain-logloss:0.606798\ttest-auc:0.716678\ttest-logloss:0.616137\n",
      "[49]\ttrain-auc:0.732838\ttrain-logloss:0.606292\ttest-auc:0.716684\ttest-logloss:0.615847\n",
      "[50]\ttrain-auc:0.733739\ttrain-logloss:0.605718\ttest-auc:0.717282\ttest-logloss:0.615445\n",
      "[51]\ttrain-auc:0.734251\ttrain-logloss:0.605167\ttest-auc:0.717671\ttest-logloss:0.615024\n",
      "[52]\ttrain-auc:0.735044\ttrain-logloss:0.604434\ttest-auc:0.718592\ttest-logloss:0.614359\n",
      "[53]\ttrain-auc:0.735689\ttrain-logloss:0.603926\ttest-auc:0.71837\ttest-logloss:0.614323\n",
      "[54]\ttrain-auc:0.736532\ttrain-logloss:0.603375\ttest-auc:0.719011\ttest-logloss:0.613904\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-a071bc8c5323>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                 \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                 evals=[(pool, 'train'), (pool_test, 'test')])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/cs/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m--> 894\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m    895\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf = xgb.train(params,\n",
    "                pool,\n",
    "                num_boost_round=10000,\n",
    "                early_stopping_rounds=20, \n",
    "                evals=[(pool, 'train'), (pool_test, 'test')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7998615592029301"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(pool.get_label(), clf.predict(pool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7403906914838165"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(pool_test.get_label(), clf.predict(pool_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10) 0.667625840431483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maximus/anaconda3/envs/cs/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(max_depth=12, n_estimators=90)\n",
    "model.fit(X_train, Y_train)\n",
    "print(n, ') ', metrics.roc_auc_score(Y_test, model.predict(X_test)), sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
