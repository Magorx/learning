{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решающее дерево своими руками\n",
    "\n",
    "Линейная регрессия далась слишком просто, давайте решать задачу регрессии с помощью дерева!\n",
    "\n",
    "Материалы по теме:\n",
    "\n",
    "https://habrahabr.ru/company/ods/blog/322534/#derevo-resheniy-v-zadache-regressii\n",
    "\n",
    "http://web.as.uky.edu/statistics/users/pbreheny/764-F11/notes/11-3.pdf\n",
    "\n",
    "https://www.dcc.fc.up.pt/~ltorgo/PhD/th3.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основной класс `RegressionDecisionTree` должен содержать:\n",
    "\n",
    "* атрибуты:\n",
    " - `max_depth`: ограничение на глубину дерева \\\\ tree depth restriction\n",
    " - `min_leaf_size`: ограничение на минимальное число объектов в листе \\\\ leaf size restriction\n",
    " - `n_samples`: размер подвыборки в вершине \\\\ amount of objects in the node\n",
    " - `n_features`: количество признаков \\\\ amount of features\n",
    "* методы:\n",
    " - `sampleImpurity_(self, X)`: возвращает меру неопределённости выборки `X` \\\\ return sample impurity of the array `X`\n",
    " - `splitSamples_(self, feature, predicate, X)`: возвращает индексы разбиения выборки `X` по признаку `feature` по порогу `predicate` на две подвыборки \\\\ return indices of `X` partition on `feature` by `predicate`\n",
    " - `findBestSplit_(self, X, y)`: возвращает индексы наилучшего разбиения выборки объектов `X` на две подвыборки; признак, по которому произведено разбиение; пороговое значение признака; меру неопределённости разбиения \\\\ return split indices of `X`; split feature; split threshold; split impurity\n",
    " - `buildTree_(self, X, y, cur_node=None)`: строит решающее дерево из вершины `cur_node` по выборке `X` \\\\ build decision tree from the node `cur_node` on the `X` objects\n",
    " - `predictSample_(self, sample, cur_node)`: предсказывает класс для объекта `sample`, начиная из вершины `cur_node` \\\\ predict class for the `sample` object\n",
    " - `fit(self, X, y)`: подготавливает данные для построения решающего дерева по выборке `X` \\\\ prepare your data for tree building\n",
    " - `predict(self, X)`: предсказывает классы для всех объектов из выборки `X` \\\\ predict classes for every object in `X`\n",
    " - `score(self, X, y)`: возвращает среднеквадратичную ошибку предсказаний по выборке `X` от истинных ответов `y` \\\\ return mean squared error of your prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RegressionDecisionTree:\n",
    "    # done\n",
    "    def __init__(self, max_depth=None, min_leaf_size=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_leaf_size = min_leaf_size\n",
    "        self.n_samples = 0\n",
    "        self.n_features = 0\n",
    "    \n",
    "    def sampleImpurity_(self, X):\n",
    "        \"\"\" find sample impurity \"\"\"\n",
    "        impurity = None\n",
    "        # your code\n",
    "        return impurity\n",
    "    \n",
    "    def splitSamples_(self, feature, predicate, X):\n",
    "        \"\"\" return split indices \"\"\"\n",
    "        # your code\n",
    "        return\n",
    "    \n",
    "    def findBestSplit_(self, X, y, sample_ind):\n",
    "        \"\"\" find feature and threshold with the best split impurity \"\"\"\n",
    "        \n",
    "        # your code    \n",
    "        \n",
    "        return # <1st part indices>, <2nd part indices>, <split feature>, <split threshold>, <split impurity>\n",
    "    \n",
    "    def buildTree_(self, X, y, cur_node=None):\n",
    "        # your code\n",
    "        return\n",
    "        \n",
    "    def predictSample_(self, sample, cur_node):\n",
    "        y_average = None\n",
    "        # your code\n",
    "        return y_average \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # число объектов в выборке X\n",
    "        self.n_samples = None # your code\n",
    "        # число признаков в выборке X\n",
    "        self.n_features = None # your code\n",
    "        # начинаем построение дерева по всей имеющейся выборке\n",
    "        self.buildTree_(X, y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        y = None\n",
    "        # your code\n",
    "        return y\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        mse = None\n",
    "        # your code\n",
    "        return mse"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
