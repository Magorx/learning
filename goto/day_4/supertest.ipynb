{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"Tweets data.csv\", encoding = \"ISO-8859-1\")\n",
    "target = tweets['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_trick(s):\n",
    "    s.lower()\n",
    "\n",
    "    #n = 25\n",
    "    #arr = np.zeros(n)\n",
    "    #for i in range(len(s) - 2):\n",
    "    #    arr[hash(s[i:i+2]) % n] += 1\n",
    "    \n",
    "    n = 200\n",
    "    tarr = np.zeros(n)\n",
    "    for i in range(len(s) - 2):\n",
    "        tarr[hash(s[i:i+2]) % n] += 1\n",
    "        \n",
    "    return pd.Series(tarr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tweets.SentimentText.apply(hash_trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'] = target\n",
    "data.drop('target', axis=1, inplace=True)\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(data, target, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6320505640451236"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best():\n",
    "    for n in range(300, 400):\n",
    "        def hash_trick(s):\n",
    "            s.lower()\n",
    "\n",
    "            #n = 25\n",
    "            #arr = np.zeros(n)\n",
    "            #for i in range(len(s) - 2):\n",
    "            #    arr[hash(s[i:i+2]) % n] += 1\n",
    "            \n",
    "            tarr = np.zeros(n)\n",
    "            gramm_size = 2\n",
    "            for i in range(len(s) - gramm_size):\n",
    "                tarr[hash(s[i:i+gramm_size]) % n] += 1\n",
    "\n",
    "            return pd.Series(tarr)\n",
    "\n",
    "        data = tweets.SentimentText.apply(hash_trick)\n",
    "        X_train, X_test, Y_train, Y_test = model_selection.train_test_split(data, target, test_size=0.25, random_state=42)\n",
    "\n",
    "        model = LogisticRegression()\n",
    "        model.fit(X_train, Y_train)\n",
    "        print(n, ') ', roc_auc_score(Y_test, model.predict(X_test)), sep = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'] = target\n",
    "data.drop('target', axis=1, inplace=True)\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200) 0.640656264088866\n",
      "201) 0.6471377078743851\n",
      "202) 0.64022389139944\n",
      "203) 0.6442121242277983\n",
      "204) 0.649953784750023\n",
      "205) 0.6426777100758293\n",
      "206) 0.6434796916771839\n",
      "207) 0.6438468503515525\n",
      "208) 0.6479067055085864\n",
      "209) 0.6482795185773241\n",
      "210) 0.6481419283143421\n",
      "211) 0.6425372926156625\n",
      "212) 0.638938459079525\n",
      "213) 0.6481913100251658\n",
      "214) 0.6392630213163129\n",
      "215) 0.6424085609038587\n",
      "216) 0.6491657506547789\n",
      "217) 0.6489761399636008\n",
      "218) 0.6435901408471942\n",
      "219) 0.641907581562754\n",
      "220) 0.6489339204856446\n",
      "221) 0.6494518630098568\n",
      "222) 0.6472225237899218\n",
      "223) 0.6415004651681768\n",
      "224) 0.643802557595661\n",
      "225) 0.6428463995078415\n",
      "226) 0.6438726720858382\n",
      "227) 0.6495779560042882\n",
      "228) 0.6454832320819781\n",
      "229) 0.6513615404681236\n",
      "230) 0.6436828729148478\n",
      "231) 0.64640357900546\n",
      "232) 0.6470474260442913\n",
      "233) 0.6454747504904245\n",
      "234) 0.6479722964832683\n",
      "235) 0.654245470076191\n",
      "236) 0.6434037343128252\n",
      "237) 0.6464597459895265\n",
      "238) 0.646607514162373\n",
      "239) 0.645716004650174\n",
      "240) 0.6480887770072723\n",
      "241) 0.6560249079841556\n",
      "242) 0.6472164924359282\n",
      "243) 0.6527907828848267\n",
      "244) 0.650640793665872\n",
      "245) 0.6482638747529029\n",
      "246) 0.652471309602971\n",
      "247) 0.6493069220341947\n",
      "248) 0.6528441226717089\n",
      "249) 0.6424202466522215\n",
      "250) 0.6549545311300796\n",
      "251) 0.6471620217701723\n",
      "252) 0.6544874781551897\n",
      "253) 0.6541335130676824\n",
      "254) 0.6546344924087871\n",
      "255) 0.6427088092448594\n",
      "256) 0.648494951002788\n",
      "257) 0.6472562616763243\n",
      "258) 0.649583987358282\n",
      "259) 0.6470413946902975\n",
      "260) 0.6552476172382129\n",
      "261) 0.6503746601708984\n",
      "262) 0.645866600020205\n",
      "263) 0.6489011249983038\n",
      "264) 0.6481507868655204\n",
      "265) 0.6488328953062495\n",
      "266) 0.6489787786809731\n",
      "267) 0.6507725410546726\n",
      "268) 0.649271110869857\n",
      "269) 0.6522737827596762\n",
      "270) 0.6527519560434921\n",
      "271) 0.6555829228243022\n",
      "272) 0.6557190052487858\n",
      "273) 0.6488528741663537\n",
      "274) 0.6503198125455179\n",
      "275) 0.6560503527588167\n",
      "276) 0.6472641778284411\n",
      "277) 0.64830289007405\n",
      "278) 0.646448248720976\n",
      "279) 0.6528867191092896\n",
      "280) 0.6597724520922013\n",
      "281) 0.6514292047207408\n",
      "282) 0.6554036785228008\n",
      "283) 0.6561004883888896\n",
      "284) 0.6550255880193184\n",
      "285) 0.658427460151598\n",
      "286) 0.6573693344853219\n",
      "287) 0.6546512671120821\n",
      "288) 0.6503931311925043\n",
      "289) 0.6506025322639744\n",
      "290) 0.6575764737990443\n",
      "291) 0.6520696591229507\n",
      "292) 0.6522911229024082\n",
      "293) 0.6544224526199448\n",
      "294) 0.6598783777467163\n",
      "295) 0.6537052869341271\n",
      "296) 0.6605844231236081\n",
      "297) 0.647775146599598\n",
      "298) 0.6552408319649698\n",
      "299) 0.6552692924166279\n"
     ]
    }
   ],
   "source": [
    "find_best()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
